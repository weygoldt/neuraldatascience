{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Neural Data Science_\n",
    "\n",
    "Lecturer: Prof. Dr. Philipp Berens\n",
    "\n",
    "Tutors: Jonas Beck, Ziwei Huang, Rita González Márquez\n",
    "\n",
    "Summer term 2023\n",
    "\n",
    "Names: FILL IN YOUR NAMES HERE\n",
    "\n",
    "# Coding Lab 6\n",
    "\n",
    "In this exercise we are going to fit a latent variable model (Poisson GPFA) to both toy data and real data from monkey primary visual cortex."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "### 1. Code \n",
    "\n",
    "The toolbox we are going to use contains an implementation of the EM algorithm to fit the poisson-gpfa. \n",
    "\n",
    "Assuming you `git clone https://github.com/mackelab/poisson-gpfa` to the notebooks/ directory and have the following directory structure:\n",
    "\n",
    "\n",
    "```\n",
    "├── data/\n",
    "│   └── nds_cl_6_data.mat\n",
    "├── notebooks\n",
    "│   ├── poisson-gpfa/\n",
    "│   └── CodingLab6.ipynb\n",
    "├── matplotlib_style.txt\n",
    "├── requirements.txt\n",
    "```\n",
    "\n",
    "then you can import the related functions via:\n",
    "\n",
    "```\n",
    "import sys\n",
    "sys.path.append('./poisson-gpfa/')\n",
    "sys.path.append('./poisson-gpfa/funs')\n",
    "\n",
    "import funs.util as util\n",
    "import funs.engine as engine\n",
    "```\n",
    "\n",
    "Change the paths if you have different directory structure. For the details of the algorithm, please refer to the thesis `hooram_thesis.pdf` from ILIAS.\n",
    "\n",
    "### 2. Data\n",
    "\n",
    "Download the data file ```nds_cl_6_data.mat``` from ILIAS and save it in a ```data/``` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2023-06-07 09:33:39CEST\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.3\n",
      "IPython version      : 8.11.0\n",
      "\n",
      "sklearn: 0.0.post1\n",
      "\n",
      "matplotlib: 3.7.1\n",
      "sys       : 3.11.3 (main, Apr  7 2023, 20:13:31) [Clang 14.0.0 (clang-1400.0.29.202)]\n",
      "numpy     : 1.24.3\n",
      "seaborn   : 0.12.2\n",
      "scipy     : 1.10.1\n",
      "\n",
      "Watermark: 2.3.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# style\n",
    "import seaborn as sns\n",
    "\n",
    "# poisson-gpfa\n",
    "import sys\n",
    "sys.path.append('./poisson-gpfa/')\n",
    "sys.path.append('./poisson-gpfa/funs')\n",
    "\n",
    "import funs.util as util\n",
    "import funs.engine as engine\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext jupyter_black\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark --time --date --timezone --updated --python --iversions --watermark -p sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"../matplotlib_style.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Generate some toy data to test the poisson-GPFA code\n",
    "\n",
    "We start by verifying our code on toy data. The cell below contains code to generate data for 30 neurons, 100 trials (1000 ms each) and 50ms bin size. The neurons' firing rate $\\lambda_k$ is assumed to be a constant $d_k$ modulated by a one-dimensional latent state $x$, which is drawn from a Gaussian process:\n",
    "\n",
    "$\\lambda_k = \\exp(c_kx + d_k)$\n",
    "\n",
    "Each neuron's weight $c_k$ is drawn randomly from a normal distribution and spike counts are sampled form a Poisson distribution with rate $\\lambda_k$.\n",
    "\n",
    "Your task is to fit a Poisson GPFA model with one latent variable to this data (see `engine.PPGPFAfit`).\n",
    "\n",
    "Hint: You can use `util.dataset?`, `engine.PPGPFAfit?` or `util.initializeParams?` to find out more about the provided package.\n",
    "\n",
    "*Grading: 3 pts*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrialDur\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbinSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdrawSameX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnumTrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mxdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mydim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdOffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfixTau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfixedTau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pgpfa'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Dataset containing multiple trials of population spike counts. A dataset is sampled from the\n",
      "Poisson-GPFA model as described by the equations\n",
      "    \n",
      "    x ~ GP(0,K(tau))            - (1)\n",
      "    y ~ Poisson(exp(Cx+d))      - (2)\n",
      "\n",
      "Attributes:\n",
      "===========\n",
      "  * self.xdim : int, latent dimensionality.\n",
      "  * self.ydim : int, number of neurons.\n",
      "  * self.data : list of dictionaries\n",
      "        The nth element of the list is a dictionary containing the data such that\n",
      "      - self.data[n]['X'] : numpy array of shape (xdim x T)\n",
      "            The true latent trajectory of trial n\n",
      "      - self.data[n]['Y'] : numpy array of shape (ydim x T)\n",
      "            The spike counts of the population of trial n\n",
      "  * self.trialDur : int\n",
      "        The duration of each trial in ms. All trials must have the same length.\n",
      "  * self.binSize : int, the size of the bin in ms.\n",
      "  * self.T : int, the number of bins in each trial.\n",
      "  * self.numTrials : int, the number of trials in the dataset.\n",
      "  * self.seed : int, seed used to generate the dataset.\n",
      "  * self.dOffset : float\n",
      "        The elements of the vector d in equation (2) are drawn from U(-2,0) + dOffset.\n",
      "  * self.drawSameX : bool, if True, all trials have the same latent trajectory.\n",
      "  * self.avgFR : float\n",
      "        Population average firing rate in Hz. Returned by the bound method self.getAvgFiringRate.\n",
      "\n",
      "Methods:\n",
      "========\n",
      "  * self.getAvgFiringRate(self) : bound method\n",
      "        Computes the average firing rate of the population in Hz and returns it as the attribute\n",
      "        self.avgFR\n",
      "  * self.plotTrajectory(self, trialToShow) : bound method\n",
      "    Plots the latent trajectory and the spike counts of trialToShow (int).\n",
      "  * self.plotParams(self) : bound method, Plots the parameters. \n",
      "\u001b[0;31mFile:\u001b[0m           ~/Documents/uni_tuebingen/neuraldatascience/notebooks/poisson-gpfa/funs/util.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "# ---------------------------------\n",
    "# simulate a training set (0.5 pts)\n",
    "# ---------------------------------\n",
    "?util.dataset\n",
    "\n",
    "\n",
    "# Initialize random number generator\n",
    "\n",
    "# Specify dataset & fitting parameters\n",
    "\n",
    "# Sample from the model (make a toy dataset)\n",
    "# raining_set ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializeParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mydim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Initializes Poisson-GPFA model parameters.\n",
      "\n",
      "Parameters:\n",
      "===========\n",
      "  * xdim       : int, latent dimensionality to fit\n",
      "  * ydim       : int, number of neurons in the dataset\n",
      "  * experiment : (optional) If a third optional argument of util.dataset object is given, \n",
      "                 the fucntion returns a dictionary of parameters obtained by performing Poisson-\n",
      "                 PCA Leave this argument empty to initialize randomly.\n",
      "Returns:\n",
      "========\n",
      "     A dictionary of model parameters.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/uni_tuebingen/neuraldatascience/notebooks/poisson-gpfa/funs/util.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "?util.initializeParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPPGPFAfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minitParams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mxdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minferenceMethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'laplace'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmaxEMiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moptimLogLamb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mCdOptimMethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TNC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtauOptimMethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TNC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mEMmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Online'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatchSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0monlineParamUpdateMethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'diag'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mhessTol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstepPow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mupdateCdJointly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfullyUpdateTau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mextractAllTraj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mextractAllTraj_trueParams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgetPredictionErr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mCdMaxIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtauMaxIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Poisson-GPFA model fit given a neural population spike data. \n",
      "\n",
      "Input Attributes:\n",
      "=================\n",
      "  * experiment : (util.dataset object), required\n",
      "    - A dataset object with the following attributes:\n",
      "        experiment.data     - A list of dictionaries in the following format:\n",
      "          experiment.data[trial]['Y'] - numpy array of shape (#time bins, # neurons)\n",
      "        experiment.T        - number of time bins, all trials must have the same length\n",
      "        experiment.trialDur - duration of each trial in ms\n",
      "        experiment.binSize  - size of bin in ms\n",
      "  \n",
      "  * initParams : (dict), required: initial parameter. \n",
      "    - Has the following fields:\n",
      "        initParams['C']   - a numpy array of shape (#neurons, #latent dimension to fit)\n",
      "        initParams['d']   - a numpy array of shape (#neurons)\n",
      "        initParams['tau'] - a numpy array of shape (#latent dimension), in seconds\n",
      "  \n",
      "  * inferenceMethod : (str), optional\n",
      "    - Specifies the posterior Gaussian approximation method used in inference. Defaults to 'laplace'.\n",
      "        inferenceMethod = 'laplace' - uses laplace approximation (mean ~= mode)\n",
      "        inferenceMethod = 'variational' - uses variational inference\n",
      "  \n",
      "  * maxEMiter : (int), optional\n",
      "    - number of maximum EM iteration, defaults to 50.\n",
      "  \n",
      "  * EMmode : (str), optional\n",
      "    - If EMmode = 'Batch', performs batch EM, where inference is performed on all available trials.\n",
      "    - If EMmode = 'Online', performs online EM, where inference is performed only on smaller number of\n",
      "      subsampled trials. User can specify further details of online EM via the init attributes\n",
      "      onlineParamUpdateMethod and priorCovOpts.\n",
      "\n",
      "  * onlineParamUpdateMethod : (str)\n",
      "    - If 'balancingGamma', parameters are updated according to \n",
      "        params_{n+1} = (gamma[n])*params_{n} + (1-gamma[n])*argmax_{params}(M_step_cost_function(params)).\n",
      "    - If 'sequentialAverage', parameters are updated according to \n",
      "        params_{n+1} = (params_{n} + argmax_{params}(M_step_cost_function(params)))/2.\n",
      "    - If 'fullyUpdateAll', parameters are updated according to\n",
      "        params_{n+1} = argmax_{params}(M_step_cost_function(params)).\n",
      "    - If 'gradientDescent', parameters are updated according to\n",
      "        params_{n+1} = params_{n} + stepSize*inv(Hessian_{params_{n}})*Gradient_{params_{n}}.\n",
      "    - If 'fullyUpdateWithPrior', parameters are updated according to\n",
      "        params_{n+1} = argmax_{params}(M_step_cost_function_with_prior(params, prior)).\n",
      "      prior is specified by the attribute priorCovOpts.\n",
      "    -- gamma is a linearly spaced decreasing sequence of length maxEMiter ranging from 0 to 1.\n",
      "  \n",
      "  * forceMaxIter : (bool), optional\n",
      "    - If True, EM iterations continue even after convergence criteria are met. Defaults to False.\n",
      "      Effective only if self.EMmode = 'Batch'.\n",
      "  \n",
      "  * verbose : (bool), optional \n",
      "    - If True, the fitting process is printed in the console.\n",
      "    \n",
      "Resulting Attributes:\n",
      "=====================\n",
      "  * optimParams - (dict), optimal parameter found\n",
      "  \n",
      "  * paramSeq - (list), a list containing the parameters found in each EM iteration\n",
      "  \n",
      "  * infRes - (dict), contains the information about inferred latent trajectories.\n",
      "      infRes['post_mean'][tr] - a numpy array of shape (xdim,T). \n",
      "                                The inferred latent trajectory of trial tr.\n",
      "      infRes['post_cov'][tr] - a numpy array of shape (xdim*T,xdim*T).\n",
      "                               The covariance of the inferred latent trajectory of trial tr.\n",
      "  \n",
      "  * posteriorLikelihood - (list), poterior likelihood at each EM iteration.\n",
      "  \n",
      "  * variationalLowerBound - (list), variational lower bound at each EM iteration. \n",
      "      This attribute only exists if inferenceMethod = 'variational'.\n",
      "\n",
      "Resulting Methods:\n",
      "==================\n",
      "  * plotTrajectory(tr) - plots the inferred trajectory and spike counts of trial tr.\n",
      "  * plotTrajectories() - plots the inferred trajectory of all trials.\n",
      "  * plotParamSeq() - plots some information about how the parameters change through EM iter.\n",
      "  * plotOptimParams() - plots the optimal parameters found.\n",
      "  * plotFitDetails() - plots some information about the fitting process as functions of EM iter.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Documents/uni_tuebingen/neuraldatascience/notebooks/poisson-gpfa/funs/engine.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?engine.PPGPFAfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# fit the model (0.5 pts)\n",
    "# -----------------------\n",
    "\n",
    "# Initialize parameters using Poisson-PCA\n",
    "\n",
    "# choose sensible parameters and run fit\n",
    "fitToy = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful functions\n",
    "def allTrialsState(fit, p):\n",
    "    \"\"\"Reshape the latent signal and the spike counts\"\"\"\n",
    "    x = np.zeros([p, 0])\n",
    "    for i in range(len(fit.infRes[\"post_mean\"])):\n",
    "        x = np.concatenate((x, fit.infRes[\"post_mean\"][i]), axis=1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def allTrialsX(training_set):\n",
    "    \"\"\"Reshape the ground truth\n",
    "    latent signal and the spike counts\"\"\"\n",
    "    x_gt = np.array([])\n",
    "    for i in range(len(training_set.data)):\n",
    "        x_gt = np.concatenate((x_gt, training_set.data[i][\"X\"][0]), axis=0)\n",
    "    return x_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the ground truth vs. inferred model\n",
    "Verify your fit by plotting both ground truth and inferred parameters for:\n",
    "1. weights C\n",
    "2. biases d\n",
    "3. latent state x \n",
    "\n",
    "Note that the sign of fitted latent state and its weights are ambiguous (you can flip both without changing the model). Make sure you correct the sign for the plot if it does not match the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All trials latent state vector\n",
    "x_est = allTrialsState(fitToy, 1)\n",
    "x_true = allTrialsX(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Plot ground truth and inferred weights `C` (0.5 pts)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "# add plot\n",
    "# consider also plotting the optimal weights as a dotted line for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Plot ground truth and inferred baises `d` (0.5 pts)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "# add plot\n",
    "# consider also plotting the optimal weights as a dotted line for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Plot ground truth and inferred latent states `x` (1pt)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 3))\n",
    "# add plot\n",
    "# plot only for a subset of trials\n",
    "# consider seperating each trial by a vertical line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Fit GPFA model to real data. \n",
    "\n",
    "We now fit the model to real data and cross-validate over the dimensionality of the latent variable.\n",
    "\n",
    "*Grading: 2 pts*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "The cell below implements loading the data and encapsulates it into a class that matches the interface of the Poisson GPFA engine. You don't need to do anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EckerDataset:\n",
    "    \"\"\"Loosy class\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        path,\n",
    "        subject_id=0,\n",
    "        ydim=55,\n",
    "        trialDur=2000,\n",
    "        binSize=100,\n",
    "        numTrials=100,\n",
    "        ydimData=False,\n",
    "        numTrData=True,\n",
    "    ):\n",
    "        # T = binSize #int(trialDur/binSize)\n",
    "        T = int(trialDur / binSize)\n",
    "        matdat = sio.loadmat(path)\n",
    "        self.matdat = matdat\n",
    "        data = []\n",
    "        trial_durs = []\n",
    "        for trial_id in range(numTrials):\n",
    "            trial_time = matdat[\"spikeTimes\"][:, trial_id][0]\n",
    "            trial_big_time = np.min(trial_time)\n",
    "            trial_end_time = np.max(trial_time)\n",
    "            trial_durs.append(trial_end_time - trial_big_time)\n",
    "        for trial_id in range(numTrials):\n",
    "            Y = []\n",
    "            spike_time = []\n",
    "            data.append(\n",
    "                {\n",
    "                    \"Y\": matdat[\"spikeCounts\"][:, :, trial_id],\n",
    "                    \"spike_time\": matdat[\"spikeTimes\"][:, trial_id],\n",
    "                }\n",
    "            )\n",
    "        self.T = T\n",
    "        self.trial_durs = trial_durs\n",
    "        self.data = data\n",
    "        self.trialDur = trialDur\n",
    "        self.binSize = binSize\n",
    "        self.numTrials = numTrials\n",
    "        self.ydim = ydim\n",
    "        util.dataset.getMeanAndVariance(self)\n",
    "        util.dataset.getAvgFiringRate(self)\n",
    "        util.dataset.getAllRaster(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/nds_cl_6_data.mat\"\n",
    "data = EckerDataset(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Poisson GPFA models and perform model comparison\n",
    "\n",
    "Split the data into 80 trials used for training and 20 trials held out for performing model comparison. On the training set, fit models using one to five latent variables. Compute the performance of each model on the held-out test set.\n",
    "\n",
    "Hint: You can use the `crossValidation` function in the Poisson GPFA package.\n",
    "\n",
    "Optional: The `crossValidation` function computes the mean-squared error on the test set, which is not ideal. The predictive log-likelihood under the Poisson model would be a better measure, which you are welcome to compute instead."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivation for log-likelihood\n",
    "\n",
    "_You can add your calculations in_ $\\LaTeX$ _here_.\n",
    "\n",
    "$p_\\lambda(x_t) = \\ldots$\n",
    "\n",
    "$L(\\lambda_k; x_1, ..., x_N) = \\ldots$ \n",
    "\n",
    "$log(L) = l(\\lambda_k; x_1, ..., x_N) = \\ldots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Perfom cross validation (1 pt)\n",
    "# ------------------------------\n",
    "\n",
    "# fit the model to the data\n",
    "xdim = 1  # number of modulators\n",
    "initParams = \n",
    "fitBatch = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the actual cross validation\n",
    "xval = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the test error\n",
    "\n",
    "Make a plot of the test error for the five different models. As a baseline, please also include the test error of a model without a latent variable. This is essentially the mean-squared error of a constant rate model (or Poisson likelihood if you did the optional part above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------------------\n",
    "# Compute and plot the test errors for the different latent variable models (0.5 + 0.5 pts)\n",
    "# -----------------------------------------------------------------------------------------\n",
    "\n",
    "train_set, test_set = util.splitTrainingTestDataset(\n",
    "    data, numTrainingTrials=80, numTestTrials=20\n",
    ")\n",
    "# compute baseline error\n",
    "baseline_error = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plot here\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "# plot model error\n",
    "\n",
    "# plot baseline\n",
    "ax.axhline(baseline_error, linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Visualization: population rasters and latent state. Use the model with a single latent state. \n",
    "\n",
    "Create a raster plot where you show for each trial the spikes of all neurons as well as the trajectory of the latent state `x` (take care of the correct time axis). Sort the neurons by their weights `c_k`. Plot only the first 20 trials.\n",
    "\n",
    "*Grading: 2 pts*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import matlib\n",
    "\n",
    "# Your plot here\n",
    "fig, axs = plt.subplots(10, 2, figsize=(14, 14))\n",
    "\n",
    "ts = np.linspace(0, 2000, 100)\n",
    "xa = 0.15\n",
    "xs = 0.7 * xa * np.sin(ts / 1000 * 3.4 * 2 * np.pi) + xa\n",
    "\n",
    "with sns.axes_style(\"ticks\"):\n",
    "    for ntrial, ax in enumerate(axs.flat):\n",
    "        x = range(50, 2000, 100)  # assume binsize of 100ms\n",
    "\n",
    "        # ------------------------\n",
    "        # plot latent state (1 pt)\n",
    "        # ------------------------\n",
    "\n",
    "        # hint: can be plotted on top of the corresponding raster\n",
    "        \n",
    "        # sort neurons by firing rate\n",
    "\n",
    "        # ----------------------------------\n",
    "        # plot raster for each neuron (1 pt)\n",
    "        # ----------------------------------\n",
    "\n",
    "        if ntrial == 0:\n",
    "            ax.legend()\n",
    "        if ntrial == 1:\n",
    "            ax.plot([1000, 2000], [-30, -30], color=\"green\")\n",
    "            ax.text(1300, -50, \"1sec\")\n",
    "        if ntrial < 2:\n",
    "            ax.plot(ts, (xs * 40) + data.ydim, \"k\", color=\"black\")\n",
    "\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4. Visualization of covariance matrix.\n",
    "\n",
    "Plot (a) the covariance matrix of the observed data as well as its approximation using (b) one and (c) five latent variable(s). Use the analytical solution for the covariance matrix of the approximation*. Note that the solution is essentially the mean and covariance of the [log-normal distribution](https://en.wikipedia.org/wiki/Log-normal_distribution).\n",
    "\n",
    "$ \\mu = \\exp(\\frac{1}{2} \\text{ diag}(CC^T)+d)$\n",
    "\n",
    "$ \\text{Cov}= \\mu\\mu^T \\odot \\exp(CC^T)+\\text{ diag}(\\mu) - \\mu\\mu^T$ \n",
    "\n",
    "*[Krumin, M., and Shoham, S. (2009). Generation of Spike Trains with Controlled Auto- and Cross-Correlation Functions. Neural Computation 21, 1642–1664](http://www.mitpressjournals.org/doi/10.1162/neco.2009.08-08-847).\n",
    "\n",
    "*Grading: 3 pts*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Complete the analytical solution for the covariance matrix of\n",
    "# the approximation using the provide equations (2 pts)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\n",
    "def cov(fit):\n",
    "    # add your code here\n",
    "    return c, mu\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Plot the covariance matrix (1 pt) of\n",
    "# (1) the observed data\n",
    "# (2) its approximation using 1 latent variable\n",
    "# (3) its approximation using 5 latent variable\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "obs_corr = np.cov(data.all_raster)\n",
    "opt_r1, mu1 = cov(xval.fits[0])\n",
    "opt_r5, mu5 = cov(xval.fits[4])\n",
    "\n",
    "vmin = -1\n",
    "vmax = 1\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 3.5))\n",
    "# add plot to visualize the differences in the covariance matrices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
