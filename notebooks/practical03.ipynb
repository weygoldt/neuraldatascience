{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import string\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import sklearn\n",
    "\n",
    "## add your packages ##\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import memory_profiler\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../results/variables\")\n",
    "figures_path = Path(\"../results/figures\")\n",
    "data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"matplotlib_style.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data\n",
    "\n",
    "We are going to use the multimodal data from the paper Scala et al. 2021 (https://www.nature.com/articles/s41586-020-2907-3#Sec7). In particular, you will work with transcriptomics and electrophysiological data. From the transcriptomics gene counts, we will only work with the exon counts for simplicity. Some of the electrophysiological features are not high-quality recordings, therefore we will also filter them out for the project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells with measured depth:     1284\n",
      "Number of cells with measured thickness: 1284\n",
      "Number of reconstructed cells:           646\n",
      "Number of slices with two cells:         69\n"
     ]
    }
   ],
   "source": [
    "# META DATA\n",
    "\n",
    "meta = pd.read_csv(data_path / \"m1_patchseq_meta_data.csv\", sep=\"\\t\")\n",
    "\n",
    "cells = meta[\"Cell\"].values\n",
    "\n",
    "layers = meta[\"Targeted layer\"].values.astype(\"str\")\n",
    "cre = meta[\"Cre\"].values\n",
    "yields = meta[\"Yield (pg/µl)\"].values\n",
    "yields[yields == \"?\"] = np.nan\n",
    "yields = yields.astype(\"float\")\n",
    "depth = meta[\"Soma depth (µm)\"].values\n",
    "depth[depth == \"Slice Lost\"] = np.nan\n",
    "depth = depth.astype(float)\n",
    "thickness = meta[\"Cortical thickness (µm)\"].values\n",
    "thickness[thickness == 0] = np.nan\n",
    "thickness = thickness.astype(float)\n",
    "traced = meta[\"Traced\"].values == \"y\"\n",
    "exclude = meta[\"Exclusion reasons\"].values.astype(str)\n",
    "exclude[exclude == \"nan\"] = \"\"\n",
    "\n",
    "mice_names = meta[\"Mouse\"].values\n",
    "mice_ages = meta[\"Mouse age\"].values\n",
    "mice_cres = np.array(\n",
    "    [\n",
    "        c if c[-1] != \"+\" and c[-1] != \"-\" else c[:-1]\n",
    "        for c in meta[\"Cre\"].values\n",
    "    ]\n",
    ")\n",
    "mice_ages = dict(zip(mice_names, mice_ages))\n",
    "mice_cres = dict(zip(mice_names, mice_cres))\n",
    "\n",
    "print(\"Number of cells with measured depth:    \", np.sum(~np.isnan(depth)))\n",
    "print(\"Number of cells with measured thickness:\", np.sum(~np.isnan(thickness)))\n",
    "print(\"Number of reconstructed cells:          \", np.sum(traced))\n",
    "\n",
    "sliceids = meta[\"Slice\"].values\n",
    "a, b = np.unique(sliceids, return_counts=True)\n",
    "assert np.all(b <= 2)\n",
    "print(\"Number of slices with two cells:        \", np.sum(b == 2))\n",
    "\n",
    "# Some consistency checks\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Date\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse age\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse gender\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse genotype\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse\"].values[sliceids == s]).size == 1\n",
    "        for s in sliceids\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcriptomic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count matrix shape (exon):   (1329, 42466)\n"
     ]
    }
   ],
   "source": [
    "# READ COUNTS\n",
    "\n",
    "data_exons = pd.read_csv(\n",
    "    data_path / \"m1_patchseq_exon_counts.csv.gz\", na_filter=False, index_col=0\n",
    ")\n",
    "exonCounts = data_exons.values.transpose()\n",
    "\n",
    "assert all(cells == data_exons.columns)\n",
    "genes = np.array(data_exons.index)\n",
    "\n",
    "print(\"Count matrix shape (exon):  \", exonCounts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20171204_sample_2</th>\n",
       "      <th>20171204_sample_4</th>\n",
       "      <th>20171204_sample_5</th>\n",
       "      <th>20171204_sample_6</th>\n",
       "      <th>20171207_sample_1</th>\n",
       "      <th>20171207_sample_2</th>\n",
       "      <th>20171207_sample_6</th>\n",
       "      <th>20171207_sample_7</th>\n",
       "      <th>20171219_sample_1</th>\n",
       "      <th>20171219_sample_2</th>\n",
       "      <th>...</th>\n",
       "      <th>20191114_sample_9</th>\n",
       "      <th>20200106_sample_1</th>\n",
       "      <th>20200106_sample_4</th>\n",
       "      <th>20200106_sample_5</th>\n",
       "      <th>20200106_sample_6</th>\n",
       "      <th>20200225_sample_2</th>\n",
       "      <th>20200225_sample_5</th>\n",
       "      <th>20200316_sample_1</th>\n",
       "      <th>20200316_sample_2</th>\n",
       "      <th>20200316_sample_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0610005C13Rik</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610006L08Rik</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610009B22Rik</th>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>1291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610009E02Rik</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610009L18Rik</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n-R5s96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n-R5s97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n-R5s98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n-TSaga9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n-TStga1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42466 rows × 1329 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               20171204_sample_2  20171204_sample_4  20171204_sample_5  \\\n",
       "0610005C13Rik                  0                  0                  0   \n",
       "0610006L08Rik                  0                  0                  0   \n",
       "0610009B22Rik                  0                 68               1291   \n",
       "0610009E02Rik                  0                  0                  0   \n",
       "0610009L18Rik                  0                  0                  0   \n",
       "...                          ...                ...                ...   \n",
       "n-R5s96                        0                  0                  0   \n",
       "n-R5s97                        0                  0                  0   \n",
       "n-R5s98                        0                  0                  0   \n",
       "n-TSaga9                       0                  0                  0   \n",
       "n-TStga1                       0                  0                  0   \n",
       "\n",
       "               20171204_sample_6  20171207_sample_1  20171207_sample_2  \\\n",
       "0610005C13Rik                  0                  0                  1   \n",
       "0610006L08Rik                  0                  0                 13   \n",
       "0610009B22Rik                  0                  0                  0   \n",
       "0610009E02Rik                  0                 30                 80   \n",
       "0610009L18Rik                  0                  0                 99   \n",
       "...                          ...                ...                ...   \n",
       "n-R5s96                        0                  0                  0   \n",
       "n-R5s97                        0                  0                  0   \n",
       "n-R5s98                        0                  0                  0   \n",
       "n-TSaga9                       0                  0                  0   \n",
       "n-TStga1                       0                  0                  0   \n",
       "\n",
       "               20171207_sample_6  20171207_sample_7  20171219_sample_1  \\\n",
       "0610005C13Rik                  0                  0                  0   \n",
       "0610006L08Rik                  0                  0                  0   \n",
       "0610009B22Rik                227                  0                  7   \n",
       "0610009E02Rik                205                  0                  0   \n",
       "0610009L18Rik                  0                380                  0   \n",
       "...                          ...                ...                ...   \n",
       "n-R5s96                        0                  0                  0   \n",
       "n-R5s97                        0                  0                  0   \n",
       "n-R5s98                        0                  0                  0   \n",
       "n-TSaga9                       0                  0                  0   \n",
       "n-TStga1                       0                  0                  0   \n",
       "\n",
       "               20171219_sample_2  ...  20191114_sample_9  20200106_sample_1  \\\n",
       "0610005C13Rik                  0  ...                  0                  0   \n",
       "0610006L08Rik                  0  ...                  0                  0   \n",
       "0610009B22Rik                 10  ...                  0                271   \n",
       "0610009E02Rik                 14  ...                  0                  0   \n",
       "0610009L18Rik                  0  ...                  0                  0   \n",
       "...                          ...  ...                ...                ...   \n",
       "n-R5s96                        0  ...                  0                  0   \n",
       "n-R5s97                        0  ...                  0                  0   \n",
       "n-R5s98                        0  ...                  0                  0   \n",
       "n-TSaga9                       0  ...                  0                  0   \n",
       "n-TStga1                       0  ...                  0                  0   \n",
       "\n",
       "               20200106_sample_4  20200106_sample_5  20200106_sample_6  \\\n",
       "0610005C13Rik                  0                  0                  1   \n",
       "0610006L08Rik                  0                  0                  0   \n",
       "0610009B22Rik                  0                  0                  0   \n",
       "0610009E02Rik                  0                  0                  0   \n",
       "0610009L18Rik                  0                  0                  0   \n",
       "...                          ...                ...                ...   \n",
       "n-R5s96                        0                  0                  0   \n",
       "n-R5s97                        0                  0                  0   \n",
       "n-R5s98                        0                  0                  0   \n",
       "n-TSaga9                       0                  0                  0   \n",
       "n-TStga1                       0                  0                  0   \n",
       "\n",
       "               20200225_sample_2  20200225_sample_5  20200316_sample_1  \\\n",
       "0610005C13Rik                  0                  0                  0   \n",
       "0610006L08Rik                  0                  0                  0   \n",
       "0610009B22Rik                  0                138                  0   \n",
       "0610009E02Rik                  0                  1                  0   \n",
       "0610009L18Rik                  0                  0                  0   \n",
       "...                          ...                ...                ...   \n",
       "n-R5s96                        0                  0                  0   \n",
       "n-R5s97                        0                  0                  0   \n",
       "n-R5s98                        0                  0                  0   \n",
       "n-TSaga9                       0                  0                  0   \n",
       "n-TStga1                       0                  0                  0   \n",
       "\n",
       "               20200316_sample_2  20200316_sample_3  \n",
       "0610005C13Rik                  0                  0  \n",
       "0610006L08Rik                  0                  0  \n",
       "0610009B22Rik                 78                 89  \n",
       "0610009E02Rik                  0                  0  \n",
       "0610009L18Rik                  0                  0  \n",
       "...                          ...                ...  \n",
       "n-R5s96                        0                  0  \n",
       "n-R5s97                        0                  0  \n",
       "n-R5s98                        0                  0  \n",
       "n-TSaga9                       0                  0  \n",
       "n-TStga1                       0                  0  \n",
       "\n",
       "[42466 rows x 1329 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_exons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENE LENGTH\n",
    "\n",
    "data = pd.read_csv(data_path / \"gene_lengths.txt\")\n",
    "assert all(data[\"GeneID\"] == genes)\n",
    "exonLengths = data[\"exon_bp\"].values\n",
    "intronLengths = data[\"intron_bp\"].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = np.load(data_path / \"cluster_colors.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1329,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_colors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_type = np.load(data_path / \"rna_type.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1329,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rna_type.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(data_path / \"dict_rna_type_colors.pkl\", \"rb\")\n",
    "dict_rna_type_colors = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_rna_type_colors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electrophysiological features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells with ephys data: 1328\n"
     ]
    }
   ],
   "source": [
    "# EPHYS DATA\n",
    "\n",
    "ephysData = pd.read_csv(data_path / \"m1_patchseq_ephys_features.csv\")\n",
    "ephysNames = np.array(ephysData.columns[1:]).astype(str)\n",
    "ephysCells = ephysData[\"cell id\"].values\n",
    "ephysData = ephysData.values[:, 1:].astype(\"float\")\n",
    "names2ephys = dict(zip(ephysCells, ephysData))\n",
    "ephysData = np.array(\n",
    "    [\n",
    "        names2ephys[c] if c in names2ephys else ephysData[0] * np.nan\n",
    "        for c in cells\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Number of cells with ephys data:\", np.sum(np.isin(cells, ephysCells)))\n",
    "\n",
    "assert np.sum(~np.isin(ephysCells, cells)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1329, 29)\n",
      "(1320, 17)\n"
     ]
    }
   ],
   "source": [
    "# Filtering ephys data\n",
    "\n",
    "features_exclude = [\n",
    "    \"Afterdepolarization (mV)\",\n",
    "    \"AP Fano factor\",\n",
    "    \"ISI Fano factor\",\n",
    "    \"Latency @ +20pA current (ms)\",\n",
    "    \"Wildness\",\n",
    "    \"Spike frequency adaptation\",\n",
    "    \"Sag area (mV*s)\",\n",
    "    \"Sag time (s)\",\n",
    "    \"Burstiness\",\n",
    "    \"AP amplitude average adaptation index\",\n",
    "    \"ISI average adaptation index\",\n",
    "    \"Rebound number of APs\",\n",
    "]\n",
    "features_log = [\n",
    "    \"AP coefficient of variation\",\n",
    "    \"ISI coefficient of variation\",\n",
    "    \"ISI adaptation index\",\n",
    "    \"Latency (ms)\",\n",
    "]\n",
    "\n",
    "X = ephysData\n",
    "print(X.shape)\n",
    "for e in features_log:\n",
    "    X[:, ephysNames == e] = np.log(X[:, ephysNames == e])\n",
    "X = X[:, ~np.isin(ephysNames, features_exclude)]\n",
    "\n",
    "keepcells = ~np.isnan(np.sum(X, axis=1))\n",
    "X = X[keepcells, :]\n",
    "print(X.shape)\n",
    "\n",
    "X = X - X.mean(axis=0)\n",
    "ephysData_filtered = X / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(ephysData_filtered))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research questions to investigate\n",
    "\n",
    "**1) Inspect the data computing different statistics.** Keep in mind that the data is read counts, not UMI, so it is not supposed to follow a Poisson distribution.\n",
    "\n",
    "**2) Normalize and transform the data.** There are several ways of normalizing the data (Raw, CPM, CPMedian, RPKM, see https://www.reneshbedre.com/blog/expression_units.html, https://translational-medicine.biomedcentral.com/articles/10.1186/s12967-021-02936-w). Take into account that there are certain normalizations that only make sense for UMI data. You also explored different transformations in the assignment (none, log, sqrt). Compare how the different transformations change the two-dimensional visualization.\n",
    "\n",
    "**3) Two-dimensional visualization.** Try different methods (t-SNE, UMAP) / parameters (exagg., perplex.) for visualizations. Compare them using quantitative metrics (e.g., distance correlation, kNN accuracy/recall in high-dim vs. two-dim). Think about also using the electrophysiological features for different visualizations.\n",
    "\n",
    "**4) Clustering.** Try different clustering methods (leiden, GMM). Implement a negative binomial mixture model. For that you can follow a similar method that what is described in Harris et al. 2018 (https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2006387#abstract0), with fixed r (r=2) and S (set of important genes). Evaluate your clustering results (metrics, compare number of clusters to original labels,...).\n",
    "\n",
    "**5) Correlation in between electrophysiological features and genes/PCs.** Find correlations and a way of visualizing them.\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
